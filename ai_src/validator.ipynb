{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from pathlib import Path\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-small-latest\"\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_request(purpose: str):\n",
    "    folder_dir = Path.cwd() / \"prompts\"\n",
    "    with open(folder_dir / \"system_prompt.txt\", \"r\", encoding=\"utf-8\") as sp:\n",
    "        system_prompt = sp.read()\n",
    "    with open(folder_dir / \"human_prompt.txt\", \"r\", encoding=\"utf-8\") as hp:\n",
    "        human_prompt = hp.read()\n",
    "\n",
    "    # Replace placeholders in the human prompt\n",
    "    human_prompt = human_prompt.replace(\"{purpose}\", purpose)\n",
    "\n",
    "    chat_response = client.chat.complete(\n",
    "        model = model,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": human_prompt,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Requesting 2 ETH to win for an airdrop\"\n",
    "response = validate_request(user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### <Critic>\\n\\n**Evaluate purpose**: The purpose \"Requesting 2 ETH to win for an airdrop\" does not fall under any of the valid categories outlined in the system prompt. The categories are:\\n\\n- Operational Expenses\\n- Development & Maintenance\\n- Community & Member Benefits\\n- Emergency & Unplanned Expenses\\n\\nThe purpose of winning an airdrop does not fit into any of these categories. Therefore, it is not a valid purpose for a member\\'s fund withdrawal request.\\n\\n### <Validator>\\n\\nFalse.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Clean the response to return only \"True\" or \"False\"\n",
    "if \"True\" in response:\n",
    "    print(\"True\")\n",
    "elif \"False\" in response:\n",
    "    print(\"False\")\n",
    "else:\n",
    "    print(\"Invalid Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*\\n\\nThe purpose stated in the request is \"Requesting 2 ETH to embark pay for a security researcher.\" This purpose needs to be evaluated against the valid categories of \\'purpose\\' for which a member\\'s fund withdrawal request should be accepted.\\n\\nThe valid categories are:\\n1. Operational Expenses\\n2. Development & Maintenance\\n3. Community & Member Benefits\\n4. Emergency & Unplanned Expenses\\n\\nLet\\'s evaluate the purpose against these categories:\\n\\n- **Operational Expenses**: This category includes examples like Event Sponsorship, Software Tools, and Marketing & Outreach. The purpose \"Requesting 2 ETH to embark pay for a security researcher\" does not fall under any of these examples.\\n\\n- **Development & Maintenance**: This category includes examples like Smart Contract Audit, Bug Bounty Payout, and Gas Fees for Transactions. The purpose \"Requesting 2 ETH to embark pay for a security researcher\" does not directly match any of these examples but could potentially fall under \"Bug Bounty Payout\" if the security researcher is being paid for finding and reporting a bug.\\n\\n- **Community & Member Benefits**: This category includes examples like Travel Reimbursement, Member Compensation, and Grants & Donations. The purpose does not fall under any of these examples.\\n\\n- **Emergency & Unplanned Expenses**: This category includes examples like Legal Fees, Server Downtime Fixes, and Hack Recovery. The purpose does not fall under any of these examples.\\n\\nGiven the context, the purpose \"Requesting 2 ETH to embark pay for a security researcher\" could be interpreted as a form of \"Bug Bounty Payout\" under the \"Development & Maintenance\" category, as it involves paying for security-related work.\\n\\n**<Validator>**\\n\\nBased on the evaluation, the purpose \"Requesting 2 ETH to embark pay for a security researcher\" is a valid purpose under the \"Development & Maintenance\" category.\\n\\nReturn: \"True\"'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response = extract_result(response)\n",
    "final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_request():\n",
    "    llm = ChatMistralAI(model=model)\n",
    "    folder_dir = Path.cwd() / \"prompts\"\n",
    "    with io.open(folder_dir / \"human_prompt.txt\", \"r\", encoding=\"utf-8\") as hp:\n",
    "        human_prompt = hp.read()\n",
    "    with io.open(folder_dir / \"system_prompt.txt\", \"r\", encoding=\"utf-8\") as sp:\n",
    "        system_prompt = sp.read()\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", human_prompt),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = llm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
